
# device setting "cuda", "cpu"
device: cuda

# federated learning
# users:            number of users
# random_sampling:   whether or not perform random sampling before each iteration
# sampling_fraction: the fraction of users to sample
# iid:              whether the data is iid or non-iid.
# labels_per_user:    when data is assigned in a no-iid fashion.
users: 1
random_sampling: true
sampling_fraction: 1
iid: true
labels_per_user: 1

# hyperparameters and model type
# model:        "naiveMLP", "naiveCNN"
local_batch_size: 1024
lr: 1.e-4
epoch: 40
momentum: 0
performance_threshold: 0.1
model: "naiveMLP"

# compressors: signSGD, pred_rle_signSGD
# predictive: apply predictive encoding  
# take_turns: apply the trick of taking turns rto send "+" and "-"
# compressor:   "pred_rle_signSGD"
compressor:   "ideal_pred_signSGD"
# compressor:   "signSGD"
predictive:   true
take_turns:   false

# predictive:   false
# take_turns:    false

# Dataset configurations
# test_data_dir : the directory to the testDataset
# train_data_dir: the directory to the trainDataset
# sample_size:   the size of one sample [height x width/num_of_features]
# classes:      the class of the sample
record_dir:     ./record.dat
test_data_dir:  /media/kaiyue/2D8A97B87FB4A806/Datasets/MNIST/test.dat
train_data_dir: /media/kaiyue/2D8A97B87FB4A806/Datasets/MNIST/train.dat
sample_size:
- 28
- 28
classes: 10

# Log configurations
log_iters:   20
log_level:   "INFO"
log_file:    "./train.log"